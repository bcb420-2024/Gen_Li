---
title: "Assignment #1 ‚Äê Data set selection and initial Processing"
author: "Gen Li"
date: "2024-02-15"
output: 
  html_document:
    toc: true
    toc_depth: 2
bibliography: A1_reference.bib
---


# Introduction
This notebook records the initial processing of the data [GSE199089](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE199089)[@Cheng2022]. The data was found in the [GEO](https://www.ncbi.nlm.nih.gov/geo/) database. The codes in the notebook would basically perform the following steps to process the data:

- Automatically download the data
- Compute quality control statistics to assess data quality
- Map the original Gene symbols (Ensembl ID) to HUGO gene symbols and deal with abnormal situations
- Clean the data by removing outliers or data with significant errors
- Apply normalization on the data and generate the data frame as required
- interpret the result and answer questions

Generally, the data comes from a [paper](https://pubmed.ncbi.nlm.nih.gov/35534729/)[@Cheng2022] (please click the link to see the figure), which performs gene expression analysis of lung cancer H1299 cells in response to the presence or absence of glutamine or glucose or NH4+. There are 15 replicates with condition Gln/-, Glu/-, Glu/Gln, Glu/NH4+, control. They perform RNA-sequencing on each sample to obtain the gene expression counts in each replicate.

The Figure.1a in the [paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9177652/figure/F1/)[@Cheng2022] show the result from the paper, and it shows that main idea of the research, which is comparing the differential expression of genes under different treatment of glutamine or glucose or NH4+. It is easy to find that when Gln and Glu appears together, the expression level of Fatty acid and Cholesterol synthesis genes are increased.

The data has genes as its row names, sample IDs/names as its column names, each cell of the matrix contains the expression value of each gene in each sample. 

Install all necessary packages[@BiocManager]:
```{r, error=FALSE, message=FALSE, warning=FALSE}
# Check if all required packages are installed and install them if not
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

if (!require("GEOquery", quietly = TRUE))
    BiocManager::install("GEOquery")

if (!require("knitr", quietly = TRUE))
    install.packages("knitr")

if (!require("edgeR", quietly = TRUE))
    BiocManager::install("edgeR")

if (!require("biomaRt", quietly = TRUE))
    BiocManager::install("biomaRt")

library(GEOquery)
library(knitr)
library(edgeR)
library(biomaRt)
```

# Download Data
I will use the package [GEOquery](https://bioconductor.org/packages/release/bioc/html/GEOquery.html)[@GEOquery] to download the data from [GSE199089](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE199089)[@Cheng2022]. 

```{r, error=FALSE, message=FALSE, warning=FALSE}

# Check if the data has been downloaded to the current wording directory, if yes, the data will not be re-downloaded, if not the data will be downloaded into a newly-created directory
download_dir <- file.path(getwd())
dataset <- "GSE199089"


if (!file.exists(file.path(download_dir,dataset))) {
  print(paste("Downloading Data from GEO to", getwd()))
  getGEOSuppFiles(dataset, makeDirectory = TRUE, baseDir = getwd())
  print("Successfully downloaded!")
  
} else if (
  file.exists(file.path(download_dir,dataset)) 
  && file.exists(file.path(download_dir, dataset, 
                           paste(dataset, "_raw_counts.txt.gz", sep="")))) {
  print(paste("The data has already been downloaded in", getwd()))
}

# Obtain the basic information about the dataset
gse <- getGEO(dataset,GSEMatrix=FALSE)
current_gpl <- names(GPLList(gse))[1]
current_gpl_info <- Meta(getGEO(current_gpl))


```

After downloading the data, we need to got some general information about the data:

- Platform for the data: `r current_gpl_info$title`
- Last updated time: `r current_gpl_info$last_update_date`
- Organism: `r current_gpl_info$organism`

Then I need to load the data into my current R session:
```{r, error=FALSE, message=FALSE, warning=FALSE}

# Load the expression counts in
expression_matrix <- read.table(
  file.path(download_dir, dataset, paste(dataset, "_raw_counts.txt.gz", sep="")), 
  header=TRUE, check.names=TRUE)

# Check the dimension and content of the data
print(dim(expression_matrix))

```

I also want to check the content of the data:
```{r, error=FALSE, message=FALSE, warning=FALSE}
kable(expression_matrix[1:15,1:15], format = "html", align = 'c')
```

# Assess and clean and map the data
Check if there are abnormal data, and generate some summary statistics to assess the quality of the data and also filtering the data to exclude low-quality data
```{r, error=FALSE, message=FALSE, warning=FALSE}
# Check if there are negative values in the matrix
if (sum(expression_matrix < 0) != 0) {
  print("There are negative values in the matrix")
} else {
  print("No negative values found")
}

# Check if there are any NA value
if (any(is.na(expression_matrix)) == TRUE) {
  print("There are NA values in the matrix")
} else {
  print("No NA values found")
}

# Check if there are duplications in the Genes
if (length(rownames(expression_matrix)[duplicated(rownames(expression_matrix))]) == 0) {
  print("No Gene duplication")
} else {
  print("Gene Duplications found")
}

```

Calculate the minimum, first quartile, median, third quartile, mean and maximum for each replicate to get the overview of the data[@knitr]
```{r, error=FALSE, message=FALSE, warning=FALSE}
kable(t(sapply(expression_matrix[colnames(expression_matrix)], summary)), format = "html", align = 'c')
```


No significant abnormality or mistakes could be found, therefore, no need to exclude data at current time.
Also, the gene symbol in the expression matrix are Ensembl IDs, which need to be mapped to the HUGO gene symbols, which was maintained by the HUGO Gene Nomenclature Committee ([HGNC](https://www.genenames.org)). To do this, I am going to use the package [biomaRt](https://bioconductor.org/packages/release/bioc/html/biomaRt.html)[@BioMart]:

```{r, error=FALSE, message=FALSE, warning=FALSE}


# Since gene IDs in the original data are Ensembl IDs, I need to use the "ensembl" mart
ensembl <- useMart("ensembl")

# Obtain all datasets available 
datasets <- listDatasets(ensembl)
head(datasets)
```

We need to look up the datasets specific for Human, since our data comes from human
```{r, error=FALSE, message=FALSE, warning=FALSE}
# Search for human dataset and choose it
kable(head(datasets[grep(datasets$dataset, pattern = "sapiens"),]), format = "html", align = 'c')
```


```{r, error=FALSE, message=FALSE, warning=FALSE}
# Select the dataset for human
ensembl <- useDataset("hsapiens_gene_ensembl", mart=ensembl)
```

Convert the Ensembl ID to HUGO gene symbols

```{r, error=FALSE, message=FALSE, warning=FALSE}
ensg_ids <- rownames(expression_matrix)

#check to see if converted_ids.rds file exists
converted_file <- "converted_ids.rds"
if(file.exists(converted_file)){
  conversion <- readRDS(converted_file)
} else {
  
  # Convert Ensembl to HUGO
  conversion <- getBM(
    attributes = c("ensembl_gene_id","hgnc_symbol"), 
    filters = c("ensembl_gene_id"), 
    values = ensg_ids, 
    mart = ensembl)
  
  saveRDS(conversion, converted_file)
}
```

Check the genes that do not have the proper mapping to the HUGO symbol or valid Ensembl ID

```{r, error=FALSE, message=FALSE, warning=FALSE}
# Genes that do not have valid Ensembl IDs in the biomaRt dataset
nrow(expression_matrix) - length(which(rownames(expression_matrix) %in% conversion$ensembl_gene_id))

# Number of genes that has valid Ensembl ids but no proper mapping to HUGO symbol
sum(conversion$hgnc_symbol == "")

```

Compare to the total number of genes included (58395), 17025 is about 30% of all genes included, which is a large proportion of the data, I will not remove them, since removing them may cause significant influence to the analysis. But I will remove the 620 genes, since that are a small part of data and no information about them can be found, which may cause some potential influence to the analysis. Then I will continue to check if one Ensembl mapped to multiple HUGO:

```{r, error=FALSE, message=FALSE, warning=FALSE}
removed_blank_hugo <- conversion[!conversion$hgnc_symbol == "",]

# Check if one Ensembl map to multiple HUGO
one2mul <- removed_blank_hugo[duplicated(removed_blank_hugo$ensembl_gene_id),]
one2mul
```

I also want to check if one HUGO mapped by multiple Ensembl:
```{r, error=FALSE, message=FALSE, warning=FALSE}
# Check if multiple Ensembl map to one HUGO
mul2one <- removed_blank_hugo[duplicated(removed_blank_hugo$hgnc_symbol),]
mul2one
```

For these genes (both multiple Ensembl map to one HUGO and one Ensembl map to multiple HUGO), since they are in total 17 genes, which is a very small proportion of all genes included, just remove them to simplify the analysis

```{r, error=FALSE, message=FALSE, warning=FALSE}
# remove duplications of symbols in the dataframe
conversion <- conversion[!duplicated(conversion$hgnc_symbol), ]
conversion <- conversion[!duplicated(conversion$ensembl_gene_id), ]

head(conversion)

```

Copy Ensembl IDs to HUGO symbol positions for genes without proper mapping to HUGO symbols and add the mapping information back into the original gene expression data:

```{r, error=FALSE, message=FALSE, warning=FALSE}
# use Ensembl ID for genes that do not have proper HUGO mapping
for (i in 1:length(conversion$hgnc_symbol)) {
  if (conversion[i, 2] == "") {
    conversion[i, 2] <- conversion[i, 1]
  }
}

# add HUGO symbol to the expression matrix
processed_ex_matrix <- cbind(expression_matrix[conversion$ensembl_gene_id,], HUGO = conversion$hgnc_symbol)

# set row names of the expression matrix
row.names(processed_ex_matrix) <- processed_ex_matrix$HUGO

processed_ex_matrix <- processed_ex_matrix[, 1:15]
head(processed_ex_matrix)

```
# Normalization
Since genes with very low counts provide very little evidence for differential expression, we are going to remove genes with low counts, specifically, I am going to filter the genes by counts per million (CPM), because raw counts do not account for library size differences.

```{r, error=FALSE, message=FALSE, warning=FALSE}

# exclude low counts with threshold 6
min_threshold_sample <- 6
data_matrix <- as.matrix(processed_ex_matrix)
genes_remained <- rowSums(cpm(data_matrix) > 1) > min_threshold_sample
filtered_data_matrix <- data_matrix[genes_remained,]
head(filtered_data_matrix)

```


Here we generate two density plots before and after excluding low count genes for comparison:

```{r, error=FALSE, message=FALSE, warning=FALSE}
# define the function for plotting of density plot 
plot_density <- function(input_matrix, title) {
  counts_density <- apply(log2(input_matrix), 2, density)
  #calculate the limits across all the samples
  xlim <- 0
  ylim <- 0
  
  for (i in 1:length(counts_density)) {
    xlim <- range(c(xlim, counts_density[[i]]$x))
    ylim <- range(c(ylim, counts_density[[i]]$y))
  }
  cols <- rainbow(length(counts_density))
  ltys <- rep(1, length(counts_density))
    
  
  # to initialize the plot 
  plot(counts_density[[1]], xlim = xlim, ylim = ylim, type="n",
    ylab="Smoothing density of log2-CPM",
    main=title, cex.lab = 0.85)
  
  #plot each line
  for (i in 1:length(counts_density)) {
    lines(counts_density[[i]], col=cols[i], lty=ltys[i])
  }
  
  #create legend
  legend("topright", colnames(input_matrix), col=cols, lty=ltys, cex=0.75,
         border ="blue", text.col = "green4", 
         merge = TRUE, bg = "gray90")
}
```


```{r, error=FALSE, message=FALSE, warning=FALSE}
# plot density plot before exclude low
plot_density(data_matrix, "Data Distribution Before excluding low counts")
```

```{r, error=FALSE, message=FALSE, warning=FALSE}
# plot density plot after exclude low
plot_density(filtered_data_matrix, "Data Distribution After excluding low counts")

```

After seeing the difference of the data before and after excluding low counts, I am going to apply the TMM (Trimmed Mean of M-values) normalization technique to my data, since TMM is sample-based, and the data comes from a research that is focusing onn the difference between samples. The normalization uses package edgeR [@edgeR]

```{r, error=FALSE, message=FALSE, warning=FALSE}

# Create an edgeR container for RNASeq count data
d <- DGEList(counts = filtered_data_matrix)

# Calculate the normalization factors
d <- calcNormFactors(d)

# obtain the normalized data
normalized_counts <- cpm(d)

```

Here also provide a group of comparison before and after normalization:
```{r, error=FALSE, message=FALSE, warning=FALSE}
# plot density plot after normalization
plot_density(filtered_data_matrix, "Data Distribution Before Normalization")

```


```{r, error=FALSE, message=FALSE, warning=FALSE}
# plot density plot after normalization
plot_density(normalized_counts, "Data Distribution After Normalization")

```


```{r, error=FALSE, message=FALSE, warning=FALSE}
# Check the final processed data
dim(normalized_counts)
head(as.data.frame(normalized_counts))
saveRDS(as.data.frame(normalized_counts), file.path(getwd(), "normalized_expression_matrix_HUGO.rds"))
```
# Interpret and document
- **Why is the dataset of interest to you?**
Since all my undergraduate research projects are about lung cancer and I decided to choose this lung cancer cell-related  research dataset. And also, the authors give a relatively clear structure of their data and is easy to manipulate and process. Since I am computational biology track student, and the research itself combines wet experiments with computational technique well, which makes me want to explore. Also, because this is a paper published on Nature Metabolism, which means that it is likely to be an interesting research project.
  
- **What are the control and test conditions of the dataset?**
The control condition is normal lung cancer H1299 cells without adding any of glutamine (Gln) or glucose (Gluc) or NH4+. There are 4 test conditions, which are Gln/- (only glutamine), Glu/- (only glucose), Glu/Gln (both glutamine & glucose), Glu/NH4+ (glucose & NH4+)

- **How many samples in each of the conditions of your dataset?**
For each condition mentioned in the last question, 3 samples are included.

- **Were there expression values that were not unique for specific genes? How did you handle these?**
In the data I have, I checked that there is no duplicated genes. So I do not need to handle gene duplications. And there are some genes that all have expression values 0 for all samples. In the data processing steps, I did not remove them at first, then when performing the normalization, I set a threshold to remove those low counts in the data. But for other expression values such as some positive numbers that are not filtered by normalization, I did not pay specific attention to them.

- **Were there expression values that could not be mapped to current HUGO symbols?**
Yes, there are some genes can not be mapped to HUGO symbols correctly. Some Ensembl IDs can't be found in the biomaRt dataset (may caused by the retirement of old versions' Ensembl IDs or biomaRt does not collect all gene Ensembl IDs), and there are some Genes' Ensembl IDs can be found but no corresponding HUGO symbols to map.

- **Were there any outliers in your dataset? How were they handled in the originating paper? How many outliers were removed?**
When I calculate the summary statistics for the data for each sample. I found that samples Gln2 and ctrl1 have relatively high mean value for their gene expression values compared to samples with the same conditions as themselves. But the difference is not significant (not very much high compared to other samples), so I did not remove them. In the paper, the authors did not mentioned how they deal with outliers in detail, they just use a subset of the data to plot.  

- **How did you handle replicates?**
First, there is no gene duplication in the original data, so I did not do anything. After that, when mapping the Ensembl ID to HUGO symbols, there are some Ensembl IDs mapped to multiple HUGO symbols and also some HUGO symbols mapped by multiple Ensembl IDs, since they are a very tiny proportion of all the data, I removed them to eliminate the potential influence.

- **What is the final coverage of your dataset?**
The final coverage of my dataset is 13930 genes in the end, still 15 samples included in the dataset


# References










